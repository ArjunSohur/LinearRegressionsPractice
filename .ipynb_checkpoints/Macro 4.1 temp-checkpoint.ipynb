{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c1eebf",
   "metadata": {},
   "source": [
    "# SARIMA forcsating into random forest - Team MACRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a8250f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183e9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "#SARIMA\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "\n",
    "#Scikit learn\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Scikit learn in case of extrapolation\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "563e4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_forecasts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3eaea",
   "metadata": {},
   "source": [
    "# TEMPERATURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ff2d6",
   "metadata": {},
   "source": [
    "### Setting up data - Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ef44893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of dataframes\n",
    "fullData = []\n",
    "var_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d947ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MonthlyTemp.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m temp_tempdf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMonthlyTemp.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m temperature \u001b[38;5;241m=\u001b[39m temp_tempdf\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      4\u001b[0m temp_ngData \u001b[38;5;241m=\u001b[39m temperature\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MonthlyTemp.csv'"
     ]
    }
   ],
   "source": [
    "temp_tempdf = pd.read_csv(\"MonthlyTemp.csv\", skiprows=4)\n",
    "temperature = temp_tempdf.to_numpy()\n",
    "\n",
    "temp_ngData = temperature\n",
    "temp_rows, temp_cols = temp_ngData.shape\n",
    "temp_ngData2 = [0 for i in range(temp_rows)]\n",
    "\n",
    "\n",
    "for j in range(len(temp_ngData)):\n",
    "    temp = temp_ngData[j][0]\n",
    "    temp = str(temp)\n",
    "    month = int(float(temp[4:]))\n",
    "    year = int(temp[:4])\n",
    "    ready4date = str(month) + \"/1/\" + str(year)\n",
    "    dates = datetime.strptime(ready4date, \"%m/%d/%Y\")\n",
    "    temp_ngData2[j] = ([dates, temp_ngData[j][1]])\n",
    "    \n",
    "temp_ngData2 = np.array(temp_ngData2, dtype=object)\n",
    "\n",
    "temperaturedf = pd.DataFrame(temp_ngData2, columns=[\"Date\", \"Temp\"])\n",
    "\n",
    "temperaturedf[\"Temp\"] = pd.to_numeric(temperaturedf[\"Temp\"])\n",
    "\n",
    "temperaturedf = temperaturedf.resample('D', on='Date').mean()\n",
    "\n",
    "temperaturedf = temperaturedf.interpolate(method='linear', axis=0)\n",
    "\n",
    "fullData.append(temperaturedf)\n",
    "var_names.append(\"Temp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3afe8",
   "metadata": {},
   "source": [
    "### Visualization of data - Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(temperaturedf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d7a744",
   "metadata": {},
   "source": [
    "### selecting data - weekly data for certain years - Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start = datetime(2010, 1, 1)\n",
    "data_end = datetime(2020, 1, 1)\n",
    "temperaturedf = temperaturedf[data_start:data_end]\n",
    "weekly_temp = temperaturedf.resample(\"W\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c081850",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(weekly_temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6ecb3",
   "metadata": {},
   "source": [
    "### Differencing data to find \"d\" - Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20d0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P-val = \" , adfuller(weekly_temp)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963170c",
   "metadata": {},
   "source": [
    "### ACF and PACF - Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bcf445",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lag = [52, 104, 156, 208]\n",
    "\n",
    "acf = plot_acf(weekly_temp, lags = 52, zero=False)\n",
    "pacf = plot_pacf(weekly_temp, lags = 52, method='ywm', zero=False)\n",
    "\n",
    "s_acf = plot_acf(weekly_temp, lags = s_lag)\n",
    "s_pacf = plot_pacf(weekly_temp, lags = s_lag, method='ywm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867627d3",
   "metadata": {},
   "source": [
    "### Train/Test split - Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = datetime(2019, 6, 1)\n",
    "\n",
    "train_data = weekly_temp[:train_end]\n",
    "test_data = weekly_temp[train_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423ef4a",
   "metadata": {},
   "source": [
    "### Setting up orders  - Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_order = (5, 1, 2) # already stationary? - not need lag?\n",
    "my_seasonal_order = (2, 1, 2, 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad66748",
   "metadata": {},
   "source": [
    "### fitting model - Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train_data, order = my_order, seasonal_order = my_seasonal_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d0e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit()\n",
    "pred = model_fit.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7277bb4",
   "metadata": {},
   "source": [
    "### Visualizing prediction error - Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_temp = model_fit.forecast(len(test_data))\n",
    "predictions_temp = pd.DataFrame(predictions_temp, index=test_data.index)\n",
    "residuals = predictions_temp.iloc[:,0].subtract(test_data.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(residuals)\n",
    "plt.axhline(0, linestyle='--', color='k')\n",
    "plt.title('Residuals from SARIMA Model - Temperature', fontsize=20)\n",
    "plt.ylabel('Error', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a603362",
   "metadata": {},
   "source": [
    "### Visualizing prediction - Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.plot(weekly_temp)\n",
    "plt.plot(predictions_temp)\n",
    "#plt.plot(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893863ae",
   "metadata": {},
   "source": [
    "# WITHDRAWLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c11b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of dataframes\n",
    "fullData = []\n",
    "var_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e230658b",
   "metadata": {},
   "source": [
    "### Setting up data - Withdrawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of dataframes\n",
    "withd = pd.read_csv(\"Withdrawls.csv\", skiprows=105, nrows=505, usecols=[0, 1])\n",
    "\n",
    "# to np array\n",
    "withd = withd.to_numpy()\n",
    "\n",
    "# to datetime\n",
    "for j in range(len(withd)):\n",
    "    withd[j][0] = datetime.strptime(withd[j][0], '%b-%Y')\n",
    "    \n",
    "# getting the first two value\n",
    "ready4df = withd[:, [0, 1]]\n",
    "\n",
    "# converting to dataframe\n",
    "withddf = pd.DataFrame(ready4df, columns=[\"Date\", \"Withdrawal\"])\n",
    "\n",
    "# interpolating data to fill dates\n",
    "withddf[\"Withdrawal\"] = pd.to_numeric(withddf[\"Withdrawal\"])\n",
    "withddf = withddf.resample('D', on='Date').mean()\n",
    "withddf = withddf.interpolate(method='linear', axis=0)\n",
    "\n",
    "# appending to whole\n",
    "fullData.append(withddf)\n",
    "var_names.append(\"Withdrawls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f60b8",
   "metadata": {},
   "source": [
    "### Visualization of data - Withdrawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0de406",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(withddf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8768f879",
   "metadata": {},
   "source": [
    "### Selecting data - weekly data for certain years - Withdrawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start = datetime(2010, 1, 1)\n",
    "data_end = datetime(2020, 1, 1)\n",
    "withddf = withddf[data_start:data_end]\n",
    "weekly_withddf = withddf.resample(\"W\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(withddf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf11ca",
   "metadata": {},
   "source": [
    "### Differencing data to find \"d\" - Withdrawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5651e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1_weekly_withd = weekly_withddf.diff(1)[1:]\n",
    "\n",
    "plt.plot(diff1_weekly_withd)\n",
    "plt.show()\n",
    "\n",
    "print(\"P-val = \" , adfuller(diff1_weekly_withd)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b4bd8",
   "metadata": {},
   "source": [
    "### ACF and PACF - Withdrawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f328e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lag = [52, 104, 156, 208]\n",
    "\n",
    "acf = plot_acf(weekly_withddf, lags = 52, zero=False)\n",
    "pacf = plot_pacf(weekly_withddf, lags = 52, method='ywm', zero=False)\n",
    "\n",
    "s_acf = plot_acf(weekly_withddf, lags = s_lag)\n",
    "s_pacf = plot_pacf(weekly_withddf, lags = s_lag, method='ywm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca9efc",
   "metadata": {},
   "source": [
    "### Train/Test split - Withdrawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = datetime(2019, 6, 1)\n",
    "\n",
    "train_data = weekly_withddf[:train_end]\n",
    "test_data = weekly_withddf[train_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa12c7ff",
   "metadata": {},
   "source": [
    "### Setting up orders  - Withdrawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_order = (1, 1, 2)\n",
    "my_seasonal_order = (1, 1, 2, 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9faeeae",
   "metadata": {},
   "source": [
    "### fitting model - Withdrawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc20cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train_data, order = my_order, seasonal_order=my_seasonal_order)\n",
    "\n",
    "model_fit = model.fit()\n",
    "pred = model_fit.predict()\n",
    "\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ce1c3d",
   "metadata": {},
   "source": [
    "### Visualizing prediction error - Withdrawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65411f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_withd = model_fit.forecast(len(test_data))\n",
    "predictions_withd = pd.DataFrame(predictions_withd, index=test_data.index)\n",
    "residuals = predictions_withd.iloc[:,0].subtract(test_data.iloc[:,0])\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(residuals)\n",
    "plt.axhline(0, linestyle='--', color='k')\n",
    "plt.title('Residuals from SARIMA Model - Withdrawls', fontsize=20)\n",
    "plt.ylabel('Error', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7047ee",
   "metadata": {},
   "source": [
    "### Visualizing prediction - Withdrawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea16cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.plot(weekly_withddf)\n",
    "plt.plot(predictions_withd)\n",
    "#plt.plot(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453cee48",
   "metadata": {},
   "source": [
    "# STORAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2461420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of dataframes\n",
    "fullData = []\n",
    "var_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68bec34",
   "metadata": {},
   "source": [
    "### Setting up data - Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c227ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting file locally\n",
    "stordf1 = pd.read_csv(\"CSVngStorage.csv\", skiprows=2)\n",
    "\n",
    "# to np array\n",
    "stor = stordf1.to_numpy()\n",
    "\n",
    "# to datetime\n",
    "for j in range(len(stor)):\n",
    "        stor[j][0] = datetime.strptime(stor[j][0], \"%d-%b-%y\")\n",
    "        \n",
    "# getting the first two value\n",
    "ready4df = stor[:, [0, 1]]\n",
    "\n",
    "# converting to dataframe\n",
    "stordf = pd.DataFrame(ready4df, columns=[\"Date\", \"Storage\"])\n",
    "\n",
    "# interpolating data to fill dates\n",
    "stordf[\"Storage\"] = pd.to_numeric(stordf[\"Storage\"])\n",
    "stordf = stordf.resample('D', on='Date').mean()\n",
    "stordf = stordf.interpolate(method='linear', axis=0)\n",
    "\n",
    "# appending to whole\n",
    "fullData.append(stordf)\n",
    "var_names.append(\"Storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa2b4b",
   "metadata": {},
   "source": [
    "### Visualization of data - Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ed3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stordf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc373247",
   "metadata": {},
   "source": [
    "### Selecting data - weekly data for certain years - Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336831d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start = datetime(2010, 1, 1)\n",
    "data_end = datetime(2020, 1, 1)\n",
    "\n",
    "stordf = stordf[data_start:data_end]\n",
    "weekly_stordf =stordf.resample(\"W\").mean()\n",
    "\n",
    "plt.plot(stordf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d0684b",
   "metadata": {},
   "source": [
    "### Differencing data to find \"d\" - Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff1_weekly_stordf = weekly_stordf.diff(1)[1:]\n",
    "\n",
    "#plt.plot(diff1_weekly_stordf)\n",
    "#plt.show()\n",
    "\n",
    "print(\"P-val = \" , adfuller(weekly_stordf)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfaac62",
   "metadata": {},
   "source": [
    "### ACF and PACF - Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lag = [52, 104, 156, 208]\n",
    "\n",
    "acf = plot_acf(weekly_stordf, lags = 52, zero=False)\n",
    "pacf = plot_pacf(weekly_stordf, lags = 52, method='ywm', zero=False)\n",
    "\n",
    "s_acf = plot_acf(weekly_stordf, lags = s_lag)\n",
    "s_pacf = plot_pacf(weekly_stordf, lags = s_lag, method='ywm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40633a30",
   "metadata": {},
   "source": [
    "### Train/Test split - Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = datetime(2019, 6, 1)\n",
    "\n",
    "train_data = weekly_stordf[:train_end]\n",
    "test_data = weekly_stordf[train_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495475b2",
   "metadata": {},
   "source": [
    "### Setting up orders  - Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264cf226",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_order = (1, 0, 5)\n",
    "my_seasonal_order = (1, 1, 2, 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53823f89",
   "metadata": {},
   "source": [
    "### fitting model - Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train_data, order = my_order, seasonal_order=my_seasonal_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit()\n",
    "pred = model_fit.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf7fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b7e4cb",
   "metadata": {},
   "source": [
    "### Visualizing prediction error - Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_stor = model_fit.forecast(len(test_data))\n",
    "predictions_stor = pd.DataFrame(predictions_stor, index=test_data.index)\n",
    "residuals = predictions_stor.iloc[:,0].subtract(test_data.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce576ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(residuals)\n",
    "plt.axhline(0, linestyle='--', color='k')\n",
    "plt.title('Residuals from SARIMA Model - Storage', fontsize=20)\n",
    "plt.ylabel('Error', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24478d96",
   "metadata": {},
   "source": [
    "### Visualizing prediction - Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf7ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.plot(weekly_stordf)\n",
    "plt.plot(predictions_stor)\n",
    "#plt.plot(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c794d2a",
   "metadata": {},
   "source": [
    "# Random Forrest Regression with polynomial Regression Backup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212289ba",
   "metadata": {},
   "source": [
    "### Collecting local data \n",
    "This is doing the same thing as above - maybe streamline data collection process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24cc6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of dataframes\n",
    "fullData = []\n",
    "var_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6580a9",
   "metadata": {},
   "source": [
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e91e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting file locally\n",
    "price = pd.read_csv(\"Price.csv\", skiprows=4)\n",
    "\n",
    "# to np array\n",
    "data = price.to_numpy(np.dtype(datetime, float))\n",
    "\n",
    "# setting column names\n",
    "Pricedf = pd.DataFrame(data, columns=[\"Date\", \"Price\"])\n",
    "\n",
    "# putting columns to their respective type\n",
    "Pricedf[\"Date\"] = pd.to_datetime(Pricedf[\"Date\"])\n",
    "Pricedf[\"Price\"] = pd.to_numeric(Pricedf[\"Price\"])\n",
    "\n",
    "# interpolating data to fill dates\n",
    "Pricedf = Pricedf.resample('D', on='Date').mean()\n",
    "Pricedf = Pricedf.interpolate(method='linear', axis=0)\n",
    "\n",
    "# appending to whole\n",
    "fullData.append(Pricedf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa02e61",
   "metadata": {},
   "source": [
    "Withdrawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting file locally\n",
    "withd = pd.read_csv(\"Withdrawls.csv\", skiprows=105, nrows=505, usecols=[0, 1])\n",
    "\n",
    "# to np array\n",
    "withd = withd.to_numpy()\n",
    "\n",
    "# to datetime\n",
    "for j in range(len(withd)):\n",
    "    withd[j][0] = datetime.strptime(withd[j][0], '%b-%Y')\n",
    "    \n",
    "# getting the first two value\n",
    "ready4df = withd[:, [0, 1]]\n",
    "\n",
    "# converting to dataframe\n",
    "withddf = pd.DataFrame(ready4df, columns=[\"Date\", \"Withdrawal\"])\n",
    "\n",
    "# interpolating data to fill dates\n",
    "withddf[\"Withdrawal\"] = pd.to_numeric(withddf[\"Withdrawal\"])\n",
    "withddf = withddf.resample('D', on='Date').mean()\n",
    "withddf = withddf.interpolate(method='linear', axis=0)\n",
    "\n",
    "# appending to whole\n",
    "fullData.append(withddf)\n",
    "var_names.append(\"Withdrawls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beaa49b",
   "metadata": {},
   "source": [
    "Working storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0853ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting file locally\n",
    "stordf1 = pd.read_csv(\"CSVngStorage.csv\", skiprows=2)\n",
    "\n",
    "# to np array\n",
    "stor = stordf1.to_numpy()\n",
    "\n",
    "# to datetime\n",
    "for j in range(len(stor)):\n",
    "        stor[j][0] = datetime.strptime(stor[j][0], \"%d-%b-%y\")\n",
    "        \n",
    "# getting the first two value\n",
    "ready4df = stor[:, [0, 1]]\n",
    "\n",
    "# converting to dataframe\n",
    "stordf = pd.DataFrame(ready4df, columns=[\"Date\", \"Storage\"])\n",
    "\n",
    "# interpolating data to fill dates\n",
    "stordf[\"Storage\"] = pd.to_numeric(stordf[\"Storage\"])\n",
    "stordf = stordf.resample('D', on='Date').mean()\n",
    "stordf = stordf.interpolate(method='linear', axis=0)\n",
    "\n",
    "# appending to whole\n",
    "fullData.append(stordf)\n",
    "var_names.append(\"Storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfbd28c",
   "metadata": {},
   "source": [
    "Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4112ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_tempdf = pd.read_csv(\"MonthlyTemp.csv\", skiprows=4)\n",
    "temperature = temp_tempdf.to_numpy()\n",
    "\n",
    "temp_ngData = temperature\n",
    "temp_rows, temp_cols = temp_ngData.shape\n",
    "temp_ngData2 = [0 for i in range(temp_rows)]\n",
    "\n",
    "for j in range(len(temp_ngData)):\n",
    "    temp = temp_ngData[j][0]\n",
    "    temp = str(temp)\n",
    "    month = int(float(temp[4:]))\n",
    "    year = int(temp[:4])\n",
    "    ready4date = str(month) + \"/1/\" + str(year)\n",
    "    dates = datetime.strptime(ready4date, \"%m/%d/%Y\")\n",
    "    temp_ngData2[j] = ([dates, temp_ngData[j][1]])\n",
    "    \n",
    "temp_ngData2 = np.array(temp_ngData2, dtype=object)\n",
    "\n",
    "temperaturedf = pd.DataFrame(temp_ngData2, columns=[\"Date\", \"Temp Anomaly\"])\n",
    "\n",
    "temperaturedf[\"Temperature\"] = pd.to_numeric(temperaturedf[\"Temp Anomaly\"])\n",
    "\n",
    "temperaturedf = temperaturedf.resample('D', on='Date').mean()\n",
    "\n",
    "temperaturedf = temperaturedf.interpolate(method='linear', axis=0)\n",
    "\n",
    "fullData.append(temperaturedf)\n",
    "var_names.append(\"Temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2553d2d",
   "metadata": {},
   "source": [
    "### concatenation of data\n",
    "Dates are from 2011-02-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad1a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(fullData, dtype=object)\n",
    "df = pd.concat(data, axis = \"columns\")\n",
    "df = df.iloc[11323:14975, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = .25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e0a97",
   "metadata": {},
   "source": [
    "### Splitting data into sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d25577",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc[:,\"Price\"].to_numpy()\n",
    "x_train = train.loc[:, train.columns != \"Price\"].to_numpy()\n",
    "y_test = test.loc[:,\"Price\"].to_numpy()\n",
    "x_test = test.loc[:, test.columns != \"Price\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8715198d",
   "metadata": {},
   "source": [
    "### Setting up model + prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc60e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c0e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b7019",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea58b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19540301",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total = np.concatenate((y_test, y_train))\n",
    "x_total = np.concatenate((x_test, x_train))\n",
    "yt_pred = forest.predict(x_total)\n",
    "\n",
    "plt.figure(figsize=(200, 10), dpi=80)\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.plot(range(1, len(y_total)+1), y_total, c='red')\n",
    "plt.plot(range(1, len(yt_pred)+1), yt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6625790",
   "metadata": {},
   "source": [
    "### Error\n",
    "\n",
    "Notes about error:\n",
    "    \n",
    "THIS MODEL IS NOT GOOD AT EXTRAPOLATING DATA.  If an unknown situation arises and any of the data goes beyind the bounds that we have here, the prediction will be off.For that reason, this model isn't an end-all be-all.\n",
    "\n",
    "I've added a polynomial linear regression to the prediction in case any of the parameters for prediction exceed those of the training set.\n",
    "\n",
    "Also, the decision parameters that this model creates change with each run, so the errors might change slightly.\n",
    "The errors should hover around:\n",
    "MSE - .025\n",
    "MAE - .08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d010994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSerror = mean_squared_error(prediction, y_test)\n",
    "MAerror = mean_absolute_error(prediction, y_test)\n",
    "\n",
    "print(\"MSE: \" , MSerror , \"\\nMAE: \" , MAerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265190b9",
   "metadata": {},
   "source": [
    "## Real-world Prediction  with backup linear regression\n",
    "\n",
    "Enter your values here:\n",
    "\n",
    "Currently, the values are:\n",
    "[Withdrawls per month (mmBTU), working storage (mmBTU), temperature (monthly, fahrenheit)]\n",
    "- All values should be for lower 48 states in US only, as the training data was centered around the lower 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER PREDICTION VALUES HERE\n",
    "\n",
    "all_preds = [predictions_withd,predictions_stor,predictions_temp]\n",
    "\n",
    "#display(predictions_withd)\n",
    "#display(predictions_stor)\n",
    "#display(predictions_temp)\n",
    "\n",
    "Pred_vals = pd.concat([predictions_withd,predictions_stor,predictions_temp], axis=1)\n",
    "np_Pred_vals = Pred_vals\n",
    "np_Pred_vals = np_Pred_vals.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16299213",
   "metadata": {},
   "source": [
    "Finding means for extrapolation:\n",
    "\n",
    "If prediciton paramters exceed training set parameters, the program will preform a polynomial linear regression instead of utilizing the random forest data.\n",
    "\n",
    "Note that random forest is more accurate so, therefore, is more desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Change_model = False\n",
    "\n",
    "\n",
    "for i in range(np.shape(x_total)[1]):\n",
    "    if (np_Pred_vals[:,i] >= x_total[:,i].max()).any() or (np_Pred_vals[:,i] <= x_total[:,i].min()).any():\n",
    "        Change_model = True\n",
    "\n",
    "print(\"Model change: \" , Change_model)\n",
    "\n",
    "Change_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb1c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Executing appropriate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Change_model:\n",
    "    pred = forest.predict([Pred_vals])\n",
    "    print(\"Forest: \", pred)\n",
    "else:\n",
    "    poly = PolynomialFeatures(degree = 4, include_bias = False)\n",
    "    x_poly = poly.fit_transform(x_train)\n",
    "    ex_model = LinearRegression()\n",
    "    ex_model.fit(x_poly, y_train)\n",
    "    y_pred = ex_model.predict(poly.fit_transform(x_test))\n",
    "    \n",
    "    MSerror = mean_squared_error(y_pred, y_test)\n",
    "    MAerror = mean_absolute_error(y_pred, y_test)\n",
    "\n",
    "    print(\"Errors of linear regression:\\nMSE: \" , MSerror , \"\\nMAE: \" , MAerror , \"\\n\")\n",
    "    \n",
    "    predict = ex_model.predict(poly.fit_transform([Pred_vals.iloc[:,-1:]}))\n",
    "    \n",
    "    print(\"Regression: \" , predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b27283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
